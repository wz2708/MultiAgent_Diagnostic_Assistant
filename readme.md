# MultiAgents for Medical Diagnosis  
*An audit-ready, multi-agent framework for clinical diagnosis with dual-RAG retrieval and conditional reviewer gating.*

---

## ğŸŒŸ Motivation

Medical diagnosis is a common but difficult problem.  
- Medical diagnosis is inherently uncertain.
- Medical language is nuanced: **symptoms â‰  free-text**. 
- Easy to misdiagnosis due to different descriptions.

While Large Language Models (LLMs) show promise in clinical reasoning, a **single-agent system** is often:  
- Uncontrollable and purposeless in reasoning steps.  
- Difficult to **audit** or **explain**.  
- Hard to ensure reliability in critical healthcare settings  

ğŸ‘‰ We propose a **multi-agent framework** that emphasizes **transparency, interpretability, and auditability**.

---

## ğŸš€ Key Contributions

- **Reception Doctor (Student + Teacher modes)**  
  - Extracts structured symptoms and reasoning chains from raw patient text  
  - Teacher mode: enriches historical case database with *symptoms + reasoning*  
  - Student mode: standardizes patient inputs for downstream modules  

- **Dual-RAG Retrieval**  
  - Combines **UMLS ontology** (medical knowledge base) with **historical curated cases**  
  - Historical cases are iteratively updated from Reception Doctor (teaching mode)  
  - Matching is performed on structured symptoms, reducing noise from free-form language  

- **Multi-Agent Framework**  
  - *General Doctor* provides initial hypotheses  
  - *Department Criticâ€“Expert* engage in multi-round debates  
  - *Reviewers* (accuracy, coverage, interpretability, specificity) score results  

- **Conditional Reviewer Gate**  
  - Dynamically decides whether reviewer evaluation is necessary  
  - Balances efficiency and cost with reliability and auditability  

- **Interactive Web Demo**  
  - Real-time visualization of diagnostic pipeline  
  - Shows intermediate reasoning, reviewer decisions, and final fusion scores  

- **Reproducible Experiments**  
  - Extensive ablations: SingleAgent, CoT, RAG, MultiAgent  
  - Significant improvements in Top-1 accuracy and mean reciprocal rank  

---

## ğŸ—ï¸ System Overview

![System Workflow](docs/images/system_overview.png)  

**Pipeline**:  
1. **Reception Doctor** â†’ symptom extraction  
2. **Dual-RAG Retrieval** â†’ UMLS + historical case base  
3. **General Doctor** â†’ initial diagnosis hypotheses  
4. **Criticâ€“Expert debate** â†’ multi-round validation  
5. **Reviewer Gate** â†’ conditional evaluation  
6. **Final Fusion** â†’ transparent scoring & ranking  

---

## âš™ï¸ Installation

### Option 1: Docker (Recommended)
```bash
# Build and run
docker compose up --build

# Then open in browser
http://localhost:7860
```

### Option 2: Manual Installation
```bash
# Clone repo
git clone MultiAgents 
cd MultiAgents

# Install dependencies
python3.10 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run demo
streamlit run app/web_demo.py --server.port=7860
```

## ğŸ® Demo Showcase

Launch the web app â†’ input **patient symptoms** â†’ tune parameters â†’ get real-time diagnostic reasoning.

**Demo Parameters**
- *Top-K*: number of candidate diagnoses from General Doctor  
- *Reviewer lock (p_lock)*: threshold for triggering reviewer evaluation  
- *Reviewer margin*: sensitivity for reviewer intervention  
- *Fusion weights*: relative importance of doctor, reviewer, and expert  

![web_demo1](docs/images/web_demo1.png)  
![web_demo2](docs/images/web_demo2.png)  



## ğŸ“Š Experiments & Results

**Symptom â†’ Disease prediction (Top-k Accuracy & MRR):**

| Method                 | Top-1   | Top-2   | Top-3   | Mean MRR |
|-------------------------|---------|---------|---------|----------|
| SingleAgent             | 45.28%  | 14.15%  | 6.13%   | 54.40%   |
| SingleAgent + CoT       | 46.23%  | 9.91%   | 0.66%   | 53.38%   |
| SingleAgent + CoT + RAG | 74.53%  | 6.60%   | 0.47%   | 77.99%   |
| **MultiAgent (ours)**   | **96.46%** | 1.77%   | 1.77%   | **97.97%** |

ğŸ“Œ **Conclusion**: Our method dramatically improves accuracy while enabling transparent, auditable reasoning.

**How to Reproduce Experiments:**  
```bash
# run SingleAgent
python ablation_experiments/singleAgent.py

# run SingleAgentCot
python ablation_experiments/singleAgentCot.py

# run SingleAgentCotRAG
python ablation_experiments/singleAgentCotRAG.py

# run MultiAgent(our method)
python core/agent_executor.py
```
---

## ğŸ”‘ Credentials

- Requires valid API keys (e.g., OpenAI)  
- Copy `.env.example` â†’ `.env` and set:

```bash
OPENAI_API_KEY=xxxx
```

## ğŸ“š References

- Dataset: https://huggingface.co/datasets/gretelai/symptom_to_diagnosis
- UMLS Metathesaurus: https://www.nlm.nih.gov/research/umls
- HuggingFace Embedding Model: intfloat/e5-large-v2
- Streamlit Documentation: https://docs.streamlit.io

## ğŸ“‚ Project Structure
```bash
MultiAgents/
â”œâ”€â”€ app/ # Streamlit web demo (frontend + backend)
â”‚ â”œâ”€â”€ web_demo.py # Main entry for Streamlit UI
â”‚ â”œâ”€â”€ web_backend.py # Backend logic (connects agents & resource pool)
â”‚ â””â”€â”€ demo_cases.json # Predefined demo patient cases
â”‚
â”œâ”€â”€ agents/ # All agent definitions
â”‚ â”œâ”€â”€ Reception_agent.py # ReceptionDoctorAgent (symptom extraction, dual mode)
â”‚ â”œâ”€â”€ GeneralDoct_agent.py # GeneralDoctorAgent (generate candidate diagnoses)
â”‚ â”œâ”€â”€ DeptCritic_agent.py # CriticAgent (asks clarifying questions)
â”‚ â”œâ”€â”€ DeptExpert_agent.py # ExpertAgent (domain expert responses)
â”‚ â”œâ”€â”€ Reviewer_agent.py # ReviewerAgent (conditional gate evaluation)
â”‚ â””â”€â”€ Decision_agent.py # DecisionAgent (final fusion and ranking)
â”‚
â”œâ”€â”€ case_core/ # Case management & Dual-RAG retrieval
â”‚ â”œâ”€â”€ case_rag.py # Historical case retrieval (symptom-based matching)
â”‚ â””â”€â”€ umls_rag.py # UMLS retrieval for medical knowledge grounding
â”‚
â”œâ”€â”€ umls_core/ # umls management & Dual-RAG retrieval
â”‚ â”œâ”€â”€ case_rag.py # Historical case retrieval (symptom-based matching)
â”‚ â””â”€â”€ umls_rag.py # UMLS retrieval for medical knowledge grounding
â”‚
â”œâ”€â”€ case_out/ # case-RAG saving file
â”‚
â”œâ”€â”€ umls_out/ # umls-RAG saving file
â”‚
â”œâ”€â”€ core/ # Shared utilities
â”‚ â”œâ”€â”€ util.py # ResourcePool, index loading, helper functions
â”‚ â””â”€â”€ logger.py # Logging utilities (latency, tokens, costs)
â”‚
â”œâ”€â”€ config/ # Configurations
â”‚ â””â”€â”€ settings.yaml # Model setting
â”‚
â”œâ”€â”€ outputs/ # Run outputs (for experiments logs)
â”‚ â””â”€â”€ cases.json  # MultiAgent experiments logs
â”‚ â””â”€â”€ SingleAgent  # (SingleAgent ablation experiments log)
â”‚ â””â”€â”€ SingleAgentCot  # (SingleAgentCot ablation experiments log)
â”‚ â””â”€â”€ SingleAgentCotRAG  # (SingleAgentCotRAG ablation experiments log)
â”‚
â”œâ”€â”€ ablation_experiments/ # Scripts for experiments & evaluation
â”‚ â””â”€â”€ SingleAgent.py # Ablation tests (SingleAgent)
â”‚ â””â”€â”€ SingleAgentCot.py # Ablation tests (SingleAgent with Cot)
â”‚ â””â”€â”€ SingleAgentCotRAG.py # Ablation tests (SingleAgent with Cot and RAG)
â”‚
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ requirements-lock.txt # Locked versions for reproducibility
â”œâ”€â”€ Dockerfile # Docker container build file
â”œâ”€â”€ docker-compose.yml # Docker Compose setup for local deployment
â”œâ”€â”€ .env.example # Example environment variables (API keys etc.)
â””â”€â”€ README.md # Project documentation
```